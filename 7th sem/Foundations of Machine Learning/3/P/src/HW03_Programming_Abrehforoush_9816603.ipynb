{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"B Nazanin\" size=5>\n",
    "\t\t<div align=center>\n",
    "\t\t\t<font face=\"IranNastaliq\" size=30>\n",
    "\t\t\t\t<p></p>\n",
    "\t\t\t\t<p></p>\n",
    "به نام خدا\n",
    "\t\t\t\t<p></p>\n",
    "\t\t\t</font>\n",
    "\t\t\t<font color=#FF7500>\n",
    "دانشگاه صنعتی اصفهان - دانشکده مهندسی برق و کامپیوتر\n",
    "            </font>\n",
    "\t\t\t<p></p>\n",
    "\t\t\t<font color=blue>\n",
    "مبانی یادگیری ماشین\n",
    "            </font>\n",
    "\t\t\t<br />\n",
    "\t\t\t<br />\n",
    "پاییز ۱۴۰۱\n",
    "\t\t</div>\n",
    "\t\t<hr/>\n",
    "\t\t<font color=red size=6>\n",
    "\t\t\t<br />\n",
    "\t\t\t<div align=center>\t\n",
    "تکلیف کامپیوتری سوم\n",
    "            </div>\n",
    "\t\t</font>\n",
    "\t\t<font color=green size=6>\n",
    "\t\t\t<br />\n",
    "\t\t\t<div align=center>\t\n",
    "علیرضا ابره فروش\n",
    "            </div>\n",
    "\t\t</font>\n",
    "\t\t<font color=green size=6>\n",
    "\t\t\t<br />\n",
    "\t\t\t<div align=center>\t\n",
    "9816603\n",
    "            </div>\n",
    "\t\t</font>\n",
    "\t\t<br />\n",
    "\t\t<hr />\n",
    "\t\t<style type=\"text/css\" scoped>\n",
    "        p{\n",
    "        border: 1px solid #a2a9b1;background-color: #f8f9fa;display: inline-block;\n",
    "        };\n",
    "        </style>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datawig as dw\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "df = pd.DataFrame(data = np.c_[iris['data'], iris['target']],\n",
    "                     columns = iris['feature_names'] + ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0             0.222222          0.625000           0.067797          0.041667   \n",
      "1             0.166667          0.416667           0.067797          0.041667   \n",
      "2             0.111111          0.500000           0.050847          0.041667   \n",
      "3             0.083333          0.458333           0.084746          0.041667   \n",
      "4             0.194444          0.666667           0.067797          0.041667   \n",
      "..                 ...               ...                ...               ...   \n",
      "145           0.666667          0.416667           0.711864          0.916667   \n",
      "146           0.555556          0.208333           0.677966          0.750000   \n",
      "147           0.611111          0.416667           0.711864          0.791667   \n",
      "148           0.527778          0.583333           0.745763          0.916667   \n",
      "149           0.444444          0.416667           0.694915          0.708333   \n",
      "\n",
      "     target  \n",
      "0       0.0  \n",
      "1       0.0  \n",
      "2       0.0  \n",
      "3       0.0  \n",
      "4       0.0  \n",
      "..      ...  \n",
      "145     1.0  \n",
      "146     1.0  \n",
      "147     1.0  \n",
      "148     1.0  \n",
      "149     1.0  \n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_min_max_scaled = df.copy()\n",
    "\n",
    "for column in df_min_max_scaled.columns:\n",
    "    df_min_max_scaled[column] = (df_min_max_scaled[column] - df_min_max_scaled[column].min()) / (df_min_max_scaled[column].max() - df_min_max_scaled[column].min())\n",
    "\n",
    "print(df_min_max_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test =  np.split(df_min_max_scaled.sample(frac = 1, random_state = 42), [int(.8 * len(df_min_max_scaled)), int(.9 * len(df_min_max_scaled))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1.0 / (1 + np.exp(-t))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### reading data\n",
    "train_df = pd.read_csv('Q1_data/BigMart_Dataset_Trainset.csv')\n",
    "\n",
    "##### cleaning data\n",
    "#handling missing values and wrong values\n",
    "train_df[\"Item_Weight\"] = train_df[\"Item_Weight\"].replace(np.NaN, train_df[\"Item_Weight\"].mean())\n",
    "\n",
    "train_df[\"Item_Fat_Content\"] = train_df[\"Item_Fat_Content\"].replace(\"LF\", \"Low Fat\")\n",
    "train_df[\"Item_Fat_Content\"] = train_df[\"Item_Fat_Content\"].replace(\"low fat\", \"Low Fat\")\n",
    "train_df[\"Item_Fat_Content\"] = train_df[\"Item_Fat_Content\"].replace(\"reg\", \"Regular\")\n",
    "train_df[\"Item_Fat_Content\"] = train_df[\"Item_Fat_Content\"].replace({\"Low Fat\" : 1, \"Regular\" : 2})\n",
    "\n",
    "train_df[\"Outlet_Size\"] = train_df[\"Outlet_Size\"].replace({\"Small\" : 1, \"Medium\" : 2, \"High\" : 3 })\n",
    "train_df[\"Outlet_Size\"] = train_df[\"Outlet_Size\"].replace(np.NaN, np.round(train_df[\"Outlet_Size\"].mean()))\n",
    "\n",
    "train_df = pd.get_dummies(train_df, columns = [\"Item_Type\", \"Outlet_Identifier\", \"Outlet_Location_Type\", \"Outlet_Type\"])\n",
    "\n",
    "train_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi-normal distribution\n",
    "train_df[\"Item_Weight\"].hist()\n",
    "plt.title(\"Item_Weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 150)\n",
    "cor_X = train_df.loc[:, (train_df.columns != 'Item_Identifier') & (train_df.columns != 'Item_Outlet_Sales')]\n",
    "cor_y = train_df[\"Item_Outlet_Sales\"]\n",
    "rf.fit(cor_X, cor_y)\n",
    "\n",
    "sort = rf.feature_importances_.argsort()\n",
    "plt.barh(train_df.columns[sort], rf.feature_importances_[sort])\n",
    "plt.xlabel(\"Feature Importance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunctionMSE(X, y, theta):\n",
    "    m = len(y)\n",
    "    result = (1 / (2 * m)) * np.sum((np.matmul(X, theta) - y) ** 2)\n",
    "    return result\n",
    "def costFunctionMAE(X, y, theta):\n",
    "    m = len(y)\n",
    "    result = (1 / (2 * m)) * np.sum(np.abs((np.matmul(X, theta) - y)))\n",
    "    return result\n",
    "\n",
    "def BGD(X, y, theta, learning_rate = 0.01, num_epochs = 50):\n",
    "    m = len(y)\n",
    "    new_theta = theta.copy()\n",
    "    cost_history = np.zeros(num_epochs)\n",
    "    for i in range(num_epochs):\n",
    "        new_theta = new_theta - (learning_rate / m) * np.matmul(np.transpose(X), (np.matmul(X, new_theta) - y))\n",
    "        cost_history[i] = costFunctionMSE(X, y, new_theta)\n",
    "    return new_theta, cost_history\n",
    "\n",
    "\n",
    "# convert to numpy\n",
    "X = X_train_A.to_numpy()\n",
    "y = y_train_A.to_numpy()\n",
    "\n",
    "# add a column with ones for the bias value while converting it into a matrix\n",
    "X = np.column_stack(([1] * X.shape[0], X))\n",
    "\n",
    "# rows and columns\n",
    "m, n = X.shape\n",
    "\n",
    "# initial theta\n",
    "theta = np.zeros(shape = (n, 1))\n",
    "\n",
    "# run batch gradient descent\n",
    "b_new_theta, b_cost_history = BGD(X, y.reshape((len(y), 1)), theta, 0.01, 2000)\n",
    "print(b_new_theta)\n",
    "\n",
    "# plot costs\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.plot(b_cost_history)\n",
    "plt.title('Cost Function')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunctionRidge(X, y, theta, lmbd):\n",
    "    m = len(y)\n",
    "    result = (1 / m) * (np.sum((np.matmul(X, theta) - y) ** 2) + lmbd * np.dot(theta.T, theta))\n",
    "    return result\n",
    "\n",
    "def RidgeBGD(X, y, theta, learning_rate = 0.01, lmbd = 1, num_epochs = 50):\n",
    "    m = len(y)\n",
    "    new_theta = theta.copy()\n",
    "    cost_history = np.zeros(num_epochs)\n",
    "    for i in range(num_epochs):\n",
    "        new_theta = new_theta - (learning_rate / m) * np.matmul(np.transpose(X), (np.matmul(X, new_theta) - y)) + (2 / m) * lmbd * new_theta\n",
    "        cost_history[i] = costFunctionRidge(X, y, new_theta, lmbd)\n",
    "    return new_theta, cost_history\n",
    "\n",
    "# convert to numpy\n",
    "X = X_train_A.to_numpy()\n",
    "y = y_train_A.to_numpy()\n",
    "\n",
    "# add a column with ones for the bias value while converting it into a matrix\n",
    "X = np.column_stack(([1] * X.shape[0], X))\n",
    "\n",
    "# rows and columns\n",
    "m, n = X.shape\n",
    "\n",
    "# initial theta\n",
    "theta = np.zeros(shape = (n, 1))\n",
    "\n",
    "# run batch gradient descent\n",
    "r_b_new_theta, r_b_cost_history = RidgeBGD(X, y.reshape((len(y), 1)), theta, 0.01, 1, 5000)\n",
    "\n",
    "# plot costs\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.plot(r_b_cost_history)\n",
    "plt.title('Cost Function')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunctionRidge(X, y, theta, lmbd):\n",
    "    m = len(y)\n",
    "    result = (1 / m) * (np.sum((np.matmul(X, theta) - y) ** 2) + lmbd * np.dot(theta.T, theta))\n",
    "    return result\n",
    "\n",
    "def RidgeBGD(X, y, theta, learning_rate = 0.01, lmbd = 1, num_epochs = 50):\n",
    "    m = len(y)\n",
    "    new_theta = theta.copy()\n",
    "    cost_history = np.zeros(num_epochs)\n",
    "    for i in range(num_epochs):\n",
    "        new_theta = new_theta - (learning_rate / m) * np.matmul(np.transpose(X), (np.matmul(X, new_theta) - y)) + (2 / m) * lmbd * new_theta\n",
    "        cost_history[i] = costFunctionRidge(X, y, new_theta, lmbd)\n",
    "    return new_theta, cost_history\n",
    "\n",
    "# convert to numpy\n",
    "X = X_train_A.to_numpy()\n",
    "y = y_train_A.to_numpy()\n",
    "\n",
    "# add a column with ones for the bias value while converting it into a matrix\n",
    "X = np.column_stack(([1] * X.shape[0], X))\n",
    "\n",
    "# rows and columns\n",
    "m, n = X.shape\n",
    "\n",
    "# initial theta\n",
    "theta = np.zeros(shape = (n, 1))\n",
    "\n",
    "# run batch gradient descent\n",
    "r_b_new_theta, r_b_cost_history = RidgeBGD(X, y.reshape((len(y), 1)), theta, 0.01, 1, 5000)\n",
    "\n",
    "# plot costs\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.plot(r_b_cost_history)\n",
    "plt.title('Cost Function')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
