{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"B Nazanin\" size=5>\n",
    "\t\t<div align=center>\n",
    "\t\t\t<font face=\"IranNastaliq\" size=30>\n",
    "\t\t\t\t<p></p>\n",
    "\t\t\t\t<p></p>\n",
    "به نام خدا\n",
    "\t\t\t\t<p></p>\n",
    "\t\t\t</font>\n",
    "\t\t\t<font color=#FF7500>\n",
    "دانشگاه صنعتی اصفهان - دانشکده علوم ریاضی\n",
    "            </font>\n",
    "\t\t\t<p></p>\n",
    "\t\t\t<font color=blue>\n",
    "الگوریتم‌های علوم داده\n",
    "            </font>\n",
    "\t\t\t<br />\n",
    "\t\t\t<br />\n",
    "بهار ۱۴۰۲\n",
    "\t\t</div>\n",
    "\t\t<hr/>\n",
    "\t\t<font color=red size=6>\n",
    "\t\t\t<br />\n",
    "\t\t\t<div align=center>\t\n",
    "مینی‌پروژه‌ی ۵\n",
    "            </div>\n",
    "\t\t</font>\n",
    "\t\t<br />\n",
    "\t\t<hr />\n",
    "\t\t<style type=\"text/css\" scoped>\n",
    "        p{\n",
    "        border: 1px solid #a2a9b1;background-color: #f8f9fa;display: inline-block;\n",
    "        };\n",
    "        </style>\n",
    "\t\t<div>\n",
    "\t\t\t<h3>فهرست مطالب</h3>\n",
    "\t\t\t<ul style=\"margin-right: 0;\">\n",
    "                <li>\n",
    "\t\t\t\t\t<a href=\"#knn\">\n",
    "                        K-nearest neighbors algorithm\n",
    "                    </a>\n",
    "\t\t\t\t</li>\n",
    "                <li>\n",
    "\t\t\t\t\t<a href=\"#dt\">\n",
    "                       Decision Tree\n",
    "                    </a>\n",
    "\t\t\t\t</li>\n",
    "\t\t\t</ul>\n",
    "\t\t</div>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"knn\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"B Nazanin\" size=5>\n",
    "\t\t<font color=#FF7500 size=6>\n",
    "K-nearest neighbors algorithm\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "در این بخش به پیاده‌سازی الگوریتم knn می‌پردازیم.\n",
    "<br/>\n",
    "<br/><br/>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br/>\n",
    "<div id=\"sec_1\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"B Nazanin\" size=5>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "            ابتدا کتابخانه‌های مورد نیاز را import می‌کنیم.\n",
    "        <br/>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the most common element in a list\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br/>\n",
    "<div id=\"sec_1\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"B Nazanin\" size=5>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "            تابع زیر را به نحوی کامل کنید که فاصله‌ی اقلیدسی بین دو نقطه‌ی point و data را بیابد.\n",
    "        <br/>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(point, data):\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: Euclidean distance between points a & data\n",
    "    \n",
    "    # ***************************************************\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br/>\n",
    "<div id=\"sec_1\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"B Nazanin\" size=5>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "            کلاس زیر را به نحو زیر پیاده‌سازی و کامل کنید:\n",
    "        <p style='direction:rtl; text-align: right'>\n",
    "    <ul style='direction:rtl; text-align: right'>\n",
    "        <font face=\"B Nazanin\" size=5>\n",
    "        <li>\n",
    "            در تابع predict\n",
    "            به ازای هر نقطه در X_test فاصله‌ی آن را با همه‌ی نقاط موجود در X_train به دست آورید و سپس فاصله‌های به دست آمده را از کوچک به بزرگ مرتب کنید. سپس برچسب با بیشترین تکرار از میان kتای اول لیستِ فاصله‌ها را برای آن نقطه انتخاب کنید. در نهایت باید یک لیست از پیشبینی‌هایی که به روش knn برای هر یک از داده‌های تست کردید در خروجی return کنید. در صورت تمایل می‌توانید از تابع most_common که عنصر با بیشترین تکرار را برمی‌گرداند استفاده کنید. توجه شود که X_test مجموعه‌ای نقاط تست است و لزوما یک نقطه نیست. \n",
    "        </li>\n",
    "        <li>\n",
    "            در تابع evaluate با فراخوانی تابع predict برای داده‌های تست برچسب تعیین کنید و در نهایت دقت مدل را محاسبه کنید و return کنید.\n",
    "        </li>\n",
    "    </ul>\n",
    "</p>\n",
    "\t</font>\n",
    "</div>\n",
    "        </li>\n",
    "<br/>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNeighborsClassifier:\n",
    "    def __init__(self, k=5, dist_metric=euclidean):\n",
    "        self.k = k\n",
    "        self.dist_metric = dist_metric\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: Predict the class of each point in X_test using knn algorithm\n",
    "        \n",
    "        # ***************************************************\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: Predict the class of each point in X_test by calling predict function and then find the accuracy\n",
    "        \n",
    "        # ***************************************************\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br/>\n",
    "<div id=\"sec_1\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"B Nazanin\" size=5>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "            در این قسمت عملکرد الگوریتم knn را به ازای kهای از 1 تا 30 بر روی مجموعه داده‌ی iris مشاهده می‌کنید.\n",
    "        <br/>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack the iris dataset, from UCI Machine Learning Repository\n",
    "iris = datasets.load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']# Split data into train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)# Preprocess data\n",
    "ss = StandardScaler().fit(X_train)\n",
    "X_train, X_test = ss.transform(X_train), ss.transform(X_test)# Test knn model across varying ks\n",
    "accuracies = []\n",
    "ks = range(1, 30)\n",
    "for k in ks:\n",
    "    knn = KNeighborsClassifier(k=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    accuracy = knn.evaluate(X_test, y_test)\n",
    "    accuracies.append(accuracy)# Visualize accuracy vs. k\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ks, accuracies)\n",
    "ax.set(xlabel=\"k\",\n",
    "       ylabel=\"Accuracy\",\n",
    "       title=\"Performance of knn\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"dt\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"B Nazanin\" size=5>\n",
    "\t\t<font color=#FF7500 size=6>\n",
    "Decision Tree\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "\t\t\tدر این بخش با درخت تصمیم آشنا می‌شویم. قصد داريم تا به كمك تابع  DecisionTreeClassifier از كتابخانه  sklearn پايتون، يك طبقه‌بند بسازيم. مي‌خواهيم براي پيدا كردن پارامترهاي بهينه براي اين طبقه‌بند از روش  grid search استفاده كنيم. بدين منظور مي‌توانيد از GridSearchCV از كتابخانه sklearn استفاده كنيد. پارامترهاي مورد بررسي براي درخت تصميم در اين سوال به شرح زير هستند:\n",
    "\t\t\t<li>\n",
    "\t\t\t\tcriterion که می‌تواند entropy یا gini باشد.\n",
    "\t\t\t</li>\n",
    "\t\t\t<li>\n",
    "\t\t\t\tmax_depth\n",
    "\t\t\t</li>\n",
    "\t\t\t<li>\n",
    "\t\t\t\tmin_samples_split\n",
    "\t\t\t</li>\n",
    "\t\t\t<li>\n",
    "\t\t\t\tmax_leaf_nodes\n",
    "\t\t\t</li>\n",
    "<br/>\n",
    "<br/><br/>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br/>\n",
    "<div id=\"sec_1\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"B Nazanin\" size=5>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "            ابتدا کتابخانه‌های مورد نیاز را import می‌کنیم. در صورتی که کتابخانه‌ی seaborn را نصب نکرده‌اید با دستور زیر آن را نصب کنید.\n",
    "        <br/>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br/>\n",
    "<div id=\"sec_1\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"B Nazanin\" size=5>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "\t\t\tدر این قسمت مجموعه داده‌ی iris را import می‌کنیم و سپس آن را به دو بخش آموزش و آزمون تقسیم می‌کنیم.\n",
    "\t\t<br/>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "#split train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br/>\n",
    "<div id=\"sec_1\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"B Nazanin\" size=5>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "            ابتدا کتابخانه‌های مورد نیاز را import می‌کنیم. در صورتی که کتابخانه‌ی seaborn را نصب نکرده‌اید با دستور زیر آن را نصب کنید.\n",
    "        <br/>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parametrs for gridsearch\n",
    "params = {'max_leaf_nodes': list(range(2, 10)), 'min_samples_split': [2, 3, 4], 'max_depth' :  list(range(1,11)),'criterion' :['gini', 'entropy']}\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: make a Decision Tree Classifier object using DecisionTreeClassifier() function\n",
    "clf = ...\n",
    "# TODO: make a Grid Search object using GridSearchCV() passing following arguments to it (estimator = clf,  param_grid = params, cv = 5, verbose = 1)\n",
    "GS = ...\n",
    "# TODO: call the Grid Search object GS method fit() passing X_train and y_train as arguments\n",
    "\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the results of gridsearch\n",
    "print('Best Criterion:', GS.best_estimator_.get_params()['criterion'])\n",
    "print('Best max_depth:', GS.best_estimator_.get_params()['max_depth'])\n",
    "print('Best max_leaf_nodes:', GS.best_estimator_.get_params()['max_leaf_nodes'])\n",
    "print('Best min_samples_split:', GS.best_estimator_.get_params()['min_samples_split'])\n",
    "\n",
    "best_model = GS.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makeprediction usin best model founded by gridsearch\n",
    "best_model.fit(X_train, y_train)\n",
    "y_predict = best_model.predict(X_test)\n",
    "print('Accuracy of DecisionTreeClassifier is: {:.2f}'.format(accuracy_score(y_test, y_predict)*100),'%') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
