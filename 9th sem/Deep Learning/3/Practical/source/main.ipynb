{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Track1', 'Track2']\n"
     ]
    }
   ],
   "source": [
    "# Path of each track\n",
    "print(os.listdir(\"../data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_no = \"2\"\n",
    "\n",
    "dataroot = \"../data/Track\" + track_no + \"/\"\n",
    "ckptroot = \"../checkpoint/Track\" + track_no + \"/\"\n",
    "\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-5\n",
    "batch_size = 32\n",
    "num_workers = 0\n",
    "test_size = 0.8\n",
    "shuffle = True\n",
    "\n",
    "epochs = 80\n",
    "start_epoch = 1\n",
    "resume = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handy Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDevice(datas, device):\n",
    "    \"\"\"Enable cuda.\"\"\"\n",
    "    imgs, angles = datas\n",
    "    return imgs.float().to(device), angles.float().to(device)\n",
    "\n",
    "def zoomInOut(image, scale):\n",
    "    height, width, _ = image.shape\n",
    "    center = (width // 2, height // 2)\n",
    "\n",
    "    # Zoom In\n",
    "    if scale > 1:\n",
    "        new_width = int(width * scale)\n",
    "        new_height = int(height * scale)\n",
    "        resized = cv2.resize(image, (new_width, new_height))\n",
    "        \n",
    "        start_x = max(0, center[0] - width // 2)\n",
    "        start_y = max(0, center[1] - height // 2)\n",
    "        end_x = min(new_width, center[0] + width // 2)\n",
    "        end_y = min(new_height, center[1] + height // 2)\n",
    "        \n",
    "        cropped = resized[start_y:end_y, start_x:end_x]\n",
    "\n",
    "        # Ensure the cropped image has the original dimensions\n",
    "        result = np.zeros_like(image)\n",
    "        result[:cropped.shape[0], :cropped.shape[1]] = cropped\n",
    "\n",
    "    # Zoom Out\n",
    "    elif scale < 1:\n",
    "        new_width = int(width * scale)\n",
    "        new_height = int(height * scale)\n",
    "        resized = cv2.resize(image, (new_width, new_height))\n",
    "        \n",
    "        start_x = (width - new_width) // 2\n",
    "        start_y = (height - new_height) // 2\n",
    "        end_x = start_x + new_width\n",
    "        end_y = start_y + new_height\n",
    "\n",
    "        # Ensure the resized image has the original dimensions\n",
    "        result = np.zeros_like(image)\n",
    "        result[start_y:end_y, start_x:end_x] = resized\n",
    "\n",
    "    # No zoom, return original image\n",
    "    else:\n",
    "        result = image.copy()\n",
    "\n",
    "    return result\n",
    "\n",
    "def plotHist(data_dir, col = \"steering\"):\n",
    "    # reads CSV file into a single dataframe variable\n",
    "    data_df = pd.read_csv(os.path.join(data_dir, 'driving_log.csv'),\n",
    "                          names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
    "\n",
    "    # Plot histogram of all values in data_df\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(data_df[col].values.flatten(), bins=50, color='blue', alpha=0.7)\n",
    "    plt.title('Histogram of All Values of ' + col)\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate the percentage of zero values\n",
    "    zero_percentage = (data_df[col].values.flatten() == 0).sum() / len(data_df.values.flatten()) * 100\n",
    "    print(f\"Percentage of zero values: {zero_percentage:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "# def augment(dataroot, imgName, angle):\n",
    "#     \"\"\"Data augmentation.\"\"\"\n",
    "#     name = dataroot + 'IMG/' + imgName.split('\\\\')[-1]\n",
    "#     current_image = cv2.imread(name)\n",
    "\n",
    "#     if current_image is None:\n",
    "#         print(name)\n",
    "    \n",
    "#     current_image = current_image[65:-25, :, :]\n",
    "#     if np.random.rand() < 0.5:\n",
    "#         current_image = cv2.flip(current_image, 1)\n",
    "#         angle = angle * -1.0\n",
    "\n",
    "#     return current_image, angle\n",
    "\n",
    "def augment(dataroot, imgName, angle):\n",
    "    \"\"\"Data augmentation.\"\"\"\n",
    "    name = dataroot + 'IMG/' + imgName.split('\\\\')[-1]\n",
    "    current_image = cv2.imread(name)\n",
    "\n",
    "    if current_image is None:\n",
    "        print(name)\n",
    "\n",
    "    # Crop image\n",
    "    current_image = current_image[60:-25, :, :]\n",
    "\n",
    "    old_shape = current_image.shape\n",
    "    \n",
    "    # Randomly apply augmentation techniques\n",
    "    if np.random.rand() < 0.16:\n",
    "        # Flip horizontally\n",
    "        current_image = cv2.flip(current_image, 1)\n",
    "        angle = angle * -1.0\n",
    "\n",
    "    if np.random.rand() < 0.16:\n",
    "        # Zoom\n",
    "        scale_factor = np.random.uniform(0.8, 1.2)\n",
    "        current_image = zoomInOut(current_image, scale_factor)\n",
    "        # print(current_image.shape)\n",
    "\n",
    "    if np.random.rand() < 0.16:\n",
    "        # Pan (translation)\n",
    "        tx = np.random.uniform(-20, 20)\n",
    "        ty = np.random.uniform(-5, 5)\n",
    "        translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "        current_image = cv2.warpAffine(current_image, translation_matrix, (current_image.shape[1], current_image.shape[0]))\n",
    "\n",
    "    if np.random.rand() < 0.16:\n",
    "        # Rotate\n",
    "        rotation_angle = np.random.uniform(-10, 10)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D((current_image.shape[1] / 2, current_image.shape[0] / 2), rotation_angle, 1)\n",
    "        current_image = cv2.warpAffine(current_image, rotation_matrix, (current_image.shape[1], current_image.shape[0]))\n",
    "        angle += rotation_angle\n",
    "\n",
    "    if np.random.rand() < 0.16:\n",
    "        # Change brightness\n",
    "        brightness_factor = np.random.uniform(0.5, 1.5)\n",
    "        current_image = current_image * brightness_factor\n",
    "        current_image = np.clip(current_image, 0, 255)\n",
    "\n",
    "\n",
    "\n",
    "    if (old_shape != current_image.shape):\n",
    "        print(\"Image size inconsistency detected!\")\n",
    "\n",
    "    return current_image, angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, test_size):\n",
    "    \"\"\"Load training data and train validation split\"\"\"\n",
    "    # reads CSV file into a single dataframe variable\n",
    "    data_df = pd.read_csv(os.path.join(data_dir, 'driving_log.csv'),\n",
    "                          names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
    "\n",
    "    # smooth data signal with `savgol_filter`\n",
    "    data_df[\"steering\"] = signal.savgol_filter(data_df[\"steering\"].values.tolist(), 51, 11)\n",
    "\n",
    "    # Divide the data into training set and validation set\n",
    "    train_len = int(test_size * data_df.shape[0])\n",
    "    valid_len = data_df.shape[0] - train_len\n",
    "    trainset, valset = data.random_split(\n",
    "        data_df.values.tolist(), lengths=[train_len, valid_len])\n",
    "\n",
    "    return trainset, valset\n",
    "\n",
    "trainset, valset = load_data(dataroot, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, dataroot, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.dataroot = dataroot\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_samples = self.samples[index]\n",
    "        steering_angle = float(batch_samples[3])\n",
    "\n",
    "        center_img, steering_angle_center = augment(self.dataroot, batch_samples[0], steering_angle)\n",
    "        left_img, steering_angle_left     = augment(self.dataroot, batch_samples[1], steering_angle + 0.4)\n",
    "        right_img, steering_angle_right   = augment(self.dataroot, batch_samples[2], steering_angle - 0.4)\n",
    "\n",
    "        center_img = self.transform(center_img)\n",
    "        left_img   = self.transform(left_img)\n",
    "        right_img  = self.transform(right_img)\n",
    "\n",
    "        return (center_img, steering_angle_center), (left_img, steering_angle_left), (right_img, steering_angle_right)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of zero values: 6.43%\n"
     ]
    }
   ],
   "source": [
    "plotHist(dataroot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔═════════════════════╗\n",
      "║ Prepare dataset ... ║\n",
      "╚═════════════════════╝\n",
      "15502\n"
     ]
    }
   ],
   "source": [
    "print(\"╔═════════════════════╗\\n║ Prepare dataset ... ║\\n╚═════════════════════╝\")\n",
    "def data_loader(dataroot, trainset, valset, batch_size, shuffle, num_workers):\n",
    "    \"\"\"Self-Driving vehicles simulator dataset Loader.\n",
    "\n",
    "    Args:\n",
    "        trainset: training set\n",
    "        valset: validation set\n",
    "        batch_size: training set input batch size\n",
    "        shuffle: whether shuffle during training process\n",
    "        num_workers: number of workers in DataLoader\n",
    "\n",
    "    Returns:\n",
    "        trainloader (torch.utils.data.DataLoader): DataLoader for training set\n",
    "        testloader (torch.utils.data.DataLoader): DataLoader for validation set\n",
    "    \"\"\"\n",
    "    transformations = transforms.Compose(\n",
    "        [transforms.Lambda(lambda x: (x / 127.5) - 1.0)])\n",
    "\n",
    "    # Load training data and validation data\n",
    "    training_set = TripletDataset(dataroot, trainset, transformations)\n",
    "    ##\n",
    "    print(training_set.__len__())\n",
    "    ##\n",
    "    trainloader = DataLoader(training_set,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=shuffle,\n",
    "                             num_workers=num_workers)\n",
    "\n",
    "    validation_set = TripletDataset(dataroot, valset, transformations)\n",
    "    valloader = DataLoader(validation_set,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=shuffle,\n",
    "                           num_workers=num_workers)\n",
    "\n",
    "    return trainloader, valloader\n",
    "\n",
    "\n",
    "trainloader, validationloader = data_loader(dataroot,\n",
    "                                            trainset, valset,\n",
    "                                            batch_size,\n",
    "                                            shuffle,\n",
    "                                            num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔════════════════════════╗\n",
      "║ Initialize model ..... ║\n",
      "╚════════════════════════╝\n",
      "╔═══════════════════════════════╗\n",
      "║ Initializing model done ..... ║\n",
      "╚═══════════════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "class MyNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 24, 5, stride = 2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(24, 36, 5, stride = 2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(36, 48, 5, stride = 2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(48, 64, 3),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 64, 3),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(in_features = 64 * 2 * 33, out_features = 100),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(in_features = 100, out_features = 50),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(in_features = 50, out_features = 10),\n",
    "            nn.Linear(in_features = 10, out_features = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        input = input.view(input.size(0), 3, 75, 320)\n",
    "        output = self.conv_layers(input)\n",
    "        # print(output.shape)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.linear_layers(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Define model\n",
    "print(\"╔════════════════════════╗\\n║ Initialize model ..... ║\\n╚════════════════════════╝\")\n",
    "model = MyNetwork()\n",
    "print(\"╔═══════════════════════════════╗\\n║ Initializing model done ..... ║\\n╚═══════════════════════════════╝\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer and criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and criterion\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# learning rate scheduler\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30, 50], gamma=0.1)\n",
    "\n",
    "# transfer to gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume:\n",
    "    print(\"╔═══════════════════════╗\\n║ Load checkpoint ..... ║\\n╚═══════════════════════╝\")\n",
    "    checkpoint = torch.load(\"../input/pretrainedmodels/both-nvidia-model-61.h5\",\n",
    "                            map_location=lambda storage, loc: storage)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    \"\"\"Trainer.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 ckptroot,\n",
    "                 model,\n",
    "                 device,\n",
    "                 epochs,\n",
    "                 criterion,\n",
    "                 optimizer,\n",
    "                 scheduler,\n",
    "                 start_epoch,\n",
    "                 trainloader,\n",
    "                 validationloader):\n",
    "        \"\"\"Self-Driving car Trainer.\n",
    "\n",
    "        Args:\n",
    "            model:\n",
    "            device:\n",
    "            epochs:\n",
    "            criterion:\n",
    "            optimizer:\n",
    "            start_epoch:\n",
    "            trainloader:\n",
    "            validationloader:\n",
    "\n",
    "        \"\"\"\n",
    "        super(Trainer, self).__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.ckptroot = ckptroot\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.start_epoch = start_epoch\n",
    "        self.trainloader = trainloader\n",
    "        self.validationloader = validationloader\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Training process.\"\"\"\n",
    "        self.model.to(self.device)\n",
    "        for epoch in range(self.start_epoch, self.epochs + self.start_epoch):\n",
    "            \n",
    "            # Training\n",
    "            train_loss = 0.0\n",
    "            self.model.train()\n",
    "\n",
    "            for local_batch, (centers, lefts, rights) in enumerate(self.trainloader):\n",
    "                # Transfer to GPU\n",
    "                centers, lefts, rights = toDevice(centers, self.device), toDevice(\n",
    "                    lefts, self.device), toDevice(rights, self.device)\n",
    "\n",
    "                # Model computations\n",
    "                self.optimizer.zero_grad()\n",
    "                datas = [centers, lefts, rights]\n",
    "                for data in datas:\n",
    "                    imgs, angles = data\n",
    "                    # print(\"training image: \", imgs.shape)\n",
    "                    outputs = self.model(imgs)\n",
    "                    loss = self.criterion(outputs, angles.unsqueeze(1))\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    train_loss += loss.data.item()\n",
    "\n",
    "                if local_batch % 100 == 0:\n",
    "\n",
    "                    print(\"♯ Epoch: {}/{}    |    💲Loss: {}\".format(epoch, epochs, train_loss / (local_batch + 1)))\n",
    "\n",
    "            self.scheduler.step()\n",
    "\n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            valid_loss = 0\n",
    "            with torch.set_grad_enabled(False):\n",
    "                for local_batch, (centers, lefts, rights) in enumerate(self.validationloader):\n",
    "                    # Transfer to GPU\n",
    "                    centers, lefts, rights = toDevice(centers, self.device), toDevice(\n",
    "                        lefts, self.device), toDevice(rights, self.device)\n",
    "\n",
    "                    # Model computations\n",
    "                    self.optimizer.zero_grad()\n",
    "                    datas = [centers, lefts, rights]\n",
    "                    for data in datas:\n",
    "                        imgs, angles = data\n",
    "                        outputs = self.model(imgs)\n",
    "                        loss = self.criterion(outputs, angles.unsqueeze(1))\n",
    "\n",
    "                        valid_loss += loss.data.item()\n",
    "\n",
    "                    if local_batch % 100 == 0:\n",
    "                        print(\"💰Validation Loss: {}\".format(valid_loss / (local_batch + 1)))\n",
    "\n",
    "            print()\n",
    "            # Save model\n",
    "            if epoch % 5 == 0 or epoch == self.epochs + self.start_epoch - 1:\n",
    "\n",
    "                state = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': self.model.state_dict(),\n",
    "                    'optimizer': self.optimizer.state_dict(),\n",
    "                    'scheduler': self.scheduler.state_dict(),\n",
    "                }\n",
    "\n",
    "                self.save_checkpoint(state)\n",
    "\n",
    "    def save_checkpoint(self, state):\n",
    "        \"\"\"Save checkpoint.\"\"\"\n",
    "        print(\"╔═══════════════════════╗\\n║ Save checkpoint ..... ║\\n╚═══════════════════════╝\")\n",
    "        if not os.path.exists(self.ckptroot):\n",
    "            os.makedirs(self.ckptroot)\n",
    "\n",
    "        torch.save(state, self.ckptroot + 'both-nvidia-model-{}.h5'.format(state['epoch']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔══════════════════════╗\n",
      "║ Start training ..... ║\n",
      "╚══════════════════════╝\n",
      "♯ Epoch: 1/80    |    💲Loss: 16.850257396697998\n",
      "♯ Epoch: 1/80    |    💲Loss: 4.105334107754844\n",
      "♯ Epoch: 1/80    |    💲Loss: 2.763605990479538\n",
      "♯ Epoch: 1/80    |    💲Loss: 2.220140836192326\n",
      "♯ Epoch: 1/80    |    💲Loss: 1.9118129291067694\n",
      "💰Validation Loss: 0.9363619089126587\n",
      "💰Validation Loss: 1.008902090020699\n",
      "\n",
      "♯ Epoch: 2/80    |    💲Loss: 0.6767239570617676\n",
      "♯ Epoch: 2/80    |    💲Loss: 0.9190592883837105\n",
      "♯ Epoch: 2/80    |    💲Loss: 0.8455135020524708\n",
      "♯ Epoch: 2/80    |    💲Loss: 0.8873101820630884\n",
      "♯ Epoch: 2/80    |    💲Loss: 0.8560401943705028\n",
      "💰Validation Loss: 0.5395584106445312\n",
      "💰Validation Loss: 0.7234128999828112\n",
      "\n",
      "♯ Epoch: 3/80    |    💲Loss: 0.6860863566398621\n",
      "♯ Epoch: 3/80    |    💲Loss: 0.7730799473010668\n",
      "♯ Epoch: 3/80    |    💲Loss: 0.7990877977317542\n",
      "♯ Epoch: 3/80    |    💲Loss: 0.7678109416212157\n",
      "♯ Epoch: 3/80    |    💲Loss: 0.7692485940259443\n",
      "💰Validation Loss: 0.9195447266101837\n",
      "💰Validation Loss: 0.6935926337938497\n",
      "\n",
      "♯ Epoch: 4/80    |    💲Loss: 0.7199165746569633\n",
      "♯ Epoch: 4/80    |    💲Loss: 0.6749218984110521\n",
      "♯ Epoch: 4/80    |    💲Loss: 0.701769173330632\n",
      "♯ Epoch: 4/80    |    💲Loss: 0.7074396302706973\n",
      "♯ Epoch: 4/80    |    💲Loss: 0.6907111600766009\n",
      "💰Validation Loss: 0.8407129049301147\n",
      "💰Validation Loss: 0.6332115601785112\n",
      "\n",
      "♯ Epoch: 5/80    |    💲Loss: 0.6802026182413101\n",
      "♯ Epoch: 5/80    |    💲Loss: 0.7084686151235411\n",
      "♯ Epoch: 5/80    |    💲Loss: 0.6966160367896308\n",
      "♯ Epoch: 5/80    |    💲Loss: 0.6798177097252635\n",
      "♯ Epoch: 5/80    |    💲Loss: 0.6720878720710848\n",
      "💰Validation Loss: 0.3962218463420868\n",
      "💰Validation Loss: 0.5717322219273832\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 6/80    |    💲Loss: 0.5470607280731201\n",
      "♯ Epoch: 6/80    |    💲Loss: 0.6650955797643354\n",
      "♯ Epoch: 6/80    |    💲Loss: 0.6437663530272928\n",
      "♯ Epoch: 6/80    |    💲Loss: 0.6517645750825983\n",
      "♯ Epoch: 6/80    |    💲Loss: 0.6381469327315428\n",
      "💰Validation Loss: 0.6289702206850052\n",
      "💰Validation Loss: 0.6551416332621386\n",
      "\n",
      "♯ Epoch: 7/80    |    💲Loss: 0.6343045085668564\n",
      "♯ Epoch: 7/80    |    💲Loss: 0.6514425247096189\n",
      "♯ Epoch: 7/80    |    💲Loss: 0.6368591464981808\n",
      "♯ Epoch: 7/80    |    💲Loss: 0.6108960378605662\n",
      "♯ Epoch: 7/80    |    💲Loss: 0.6045718450108519\n",
      "💰Validation Loss: 0.812336340546608\n",
      "💰Validation Loss: 0.6507438363710253\n",
      "\n",
      "♯ Epoch: 8/80    |    💲Loss: 0.5648817420005798\n",
      "♯ Epoch: 8/80    |    💲Loss: 0.5995460629905804\n",
      "♯ Epoch: 8/80    |    💲Loss: 0.5875989920390186\n",
      "♯ Epoch: 8/80    |    💲Loss: 0.5782930388724883\n",
      "♯ Epoch: 8/80    |    💲Loss: 0.5756496983276044\n",
      "💰Validation Loss: 0.5623413175344467\n",
      "💰Validation Loss: 0.5567890274347645\n",
      "\n",
      "♯ Epoch: 9/80    |    💲Loss: 0.7154780328273773\n",
      "♯ Epoch: 9/80    |    💲Loss: 0.5811432255155379\n",
      "♯ Epoch: 9/80    |    💲Loss: 0.5731109643160407\n",
      "♯ Epoch: 9/80    |    💲Loss: 0.5672349717183367\n",
      "♯ Epoch: 9/80    |    💲Loss: 0.5784174132339674\n",
      "💰Validation Loss: 0.7553584352135658\n",
      "💰Validation Loss: 0.6340885231326713\n",
      "\n",
      "♯ Epoch: 10/80    |    💲Loss: 0.6279668211936951\n",
      "♯ Epoch: 10/80    |    💲Loss: 0.5684307000719675\n",
      "♯ Epoch: 10/80    |    💲Loss: 0.563066485805891\n",
      "♯ Epoch: 10/80    |    💲Loss: 0.5541105146869473\n",
      "♯ Epoch: 10/80    |    💲Loss: 0.5508810538436261\n",
      "💰Validation Loss: 0.4730761796236038\n",
      "💰Validation Loss: 0.5168476615211751\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 11/80    |    💲Loss: 0.590007521212101\n",
      "♯ Epoch: 11/80    |    💲Loss: 0.5187204774137181\n",
      "♯ Epoch: 11/80    |    💲Loss: 0.52864899940381\n",
      "♯ Epoch: 11/80    |    💲Loss: 0.5400672389250063\n",
      "♯ Epoch: 11/80    |    💲Loss: 0.5374296174623872\n",
      "💰Validation Loss: 0.6225109100341797\n",
      "💰Validation Loss: 0.520960182615436\n",
      "\n",
      "♯ Epoch: 12/80    |    💲Loss: 0.6699023991823196\n",
      "♯ Epoch: 12/80    |    💲Loss: 0.5445257604933611\n",
      "♯ Epoch: 12/80    |    💲Loss: 0.5363280626097277\n",
      "♯ Epoch: 12/80    |    💲Loss: 0.5379054310524285\n",
      "♯ Epoch: 12/80    |    💲Loss: 0.536677959995191\n",
      "💰Validation Loss: 0.632070317864418\n",
      "💰Validation Loss: 0.54634252481974\n",
      "\n",
      "♯ Epoch: 13/80    |    💲Loss: 0.48816874623298645\n",
      "♯ Epoch: 13/80    |    💲Loss: 0.5251359954697661\n",
      "♯ Epoch: 13/80    |    💲Loss: 0.5237081662858304\n",
      "♯ Epoch: 13/80    |    💲Loss: 0.5247383709266732\n",
      "♯ Epoch: 13/80    |    💲Loss: 0.5248066732692451\n",
      "💰Validation Loss: 0.6227675303816795\n",
      "💰Validation Loss: 0.4901473223794215\n",
      "\n",
      "♯ Epoch: 14/80    |    💲Loss: 0.658466026186943\n",
      "♯ Epoch: 14/80    |    💲Loss: 0.5195422774125443\n",
      "♯ Epoch: 14/80    |    💲Loss: 0.5328461000908963\n",
      "♯ Epoch: 14/80    |    💲Loss: 0.523216518118631\n",
      "♯ Epoch: 14/80    |    💲Loss: 0.5131660091070611\n",
      "💰Validation Loss: 0.6307753920555115\n",
      "💰Validation Loss: 0.5002145447058253\n",
      "\n",
      "♯ Epoch: 15/80    |    💲Loss: 0.4160372465848923\n",
      "♯ Epoch: 15/80    |    💲Loss: 0.5036050990076348\n",
      "♯ Epoch: 15/80    |    💲Loss: 0.4959902652905355\n",
      "♯ Epoch: 15/80    |    💲Loss: 0.4941428260401238\n",
      "♯ Epoch: 15/80    |    💲Loss: 0.4991089149176183\n",
      "💰Validation Loss: 0.46350356563925743\n",
      "💰Validation Loss: 0.5074021544049282\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 16/80    |    💲Loss: 0.4040708541870117\n",
      "♯ Epoch: 16/80    |    💲Loss: 0.5174142277181739\n",
      "♯ Epoch: 16/80    |    💲Loss: 0.5071430750080009\n",
      "♯ Epoch: 16/80    |    💲Loss: 0.49874718566471554\n",
      "♯ Epoch: 16/80    |    💲Loss: 0.49258716018902987\n",
      "💰Validation Loss: 0.3451041430234909\n",
      "💰Validation Loss: 0.48001785196437696\n",
      "\n",
      "♯ Epoch: 17/80    |    💲Loss: 0.7286361902952194\n",
      "♯ Epoch: 17/80    |    💲Loss: 0.49858089064312455\n",
      "♯ Epoch: 17/80    |    💲Loss: 0.4959435353602343\n",
      "♯ Epoch: 17/80    |    💲Loss: 0.49150113390133626\n",
      "♯ Epoch: 17/80    |    💲Loss: 0.4931555151651402\n",
      "💰Validation Loss: 0.4865497648715973\n",
      "💰Validation Loss: 0.524303040679286\n",
      "\n",
      "♯ Epoch: 18/80    |    💲Loss: 0.6134489923715591\n",
      "♯ Epoch: 18/80    |    💲Loss: 0.5001274263947317\n",
      "♯ Epoch: 18/80    |    💲Loss: 0.47774303986213695\n",
      "♯ Epoch: 18/80    |    💲Loss: 0.47823811334827016\n",
      "♯ Epoch: 18/80    |    💲Loss: 0.4731755392008143\n",
      "💰Validation Loss: 0.5653295367956161\n",
      "💰Validation Loss: 0.46035362831731835\n",
      "\n",
      "♯ Epoch: 19/80    |    💲Loss: 0.5003658458590508\n",
      "♯ Epoch: 19/80    |    💲Loss: 0.4852859116168601\n",
      "♯ Epoch: 19/80    |    💲Loss: 0.47797362466541987\n",
      "♯ Epoch: 19/80    |    💲Loss: 0.4793824650149211\n",
      "♯ Epoch: 19/80    |    💲Loss: 0.4787452903871153\n",
      "💰Validation Loss: 0.5300610065460205\n",
      "💰Validation Loss: 0.44637010499171104\n",
      "\n",
      "♯ Epoch: 20/80    |    💲Loss: 0.5134455040097237\n",
      "♯ Epoch: 20/80    |    💲Loss: 0.4666239574994191\n",
      "♯ Epoch: 20/80    |    💲Loss: 0.4693921432640422\n",
      "♯ Epoch: 20/80    |    💲Loss: 0.4732171534142918\n",
      "♯ Epoch: 20/80    |    💲Loss: 0.47294668814729424\n",
      "💰Validation Loss: 0.5177949965000153\n",
      "💰Validation Loss: 0.44027858780752316\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 21/80    |    💲Loss: 0.44075435400009155\n",
      "♯ Epoch: 21/80    |    💲Loss: 0.44927961436459923\n",
      "♯ Epoch: 21/80    |    💲Loss: 0.45346148738368824\n",
      "♯ Epoch: 21/80    |    💲Loss: 0.45786650938003565\n",
      "♯ Epoch: 21/80    |    💲Loss: 0.45949102770955186\n",
      "💰Validation Loss: 0.4196636900305748\n",
      "💰Validation Loss: 0.48209109651570276\n",
      "\n",
      "♯ Epoch: 22/80    |    💲Loss: 0.40897364169359207\n",
      "♯ Epoch: 22/80    |    💲Loss: 0.47825239595062663\n",
      "♯ Epoch: 22/80    |    💲Loss: 0.4665512681674601\n",
      "♯ Epoch: 22/80    |    💲Loss: 0.46570007203524294\n",
      "♯ Epoch: 22/80    |    💲Loss: 0.47036620932735707\n",
      "💰Validation Loss: 0.6084406301379204\n",
      "💰Validation Loss: 0.4622821188946762\n",
      "\n",
      "♯ Epoch: 23/80    |    💲Loss: 0.4212582930922508\n",
      "♯ Epoch: 23/80    |    💲Loss: 0.4533662999989373\n",
      "♯ Epoch: 23/80    |    💲Loss: 0.4515841797605824\n",
      "♯ Epoch: 23/80    |    💲Loss: 0.4544814038353406\n",
      "♯ Epoch: 23/80    |    💲Loss: 0.4566522164042677\n",
      "💰Validation Loss: 0.3383047953248024\n",
      "💰Validation Loss: 0.4603096892928133\n",
      "\n",
      "♯ Epoch: 24/80    |    💲Loss: 0.4970579519867897\n",
      "♯ Epoch: 24/80    |    💲Loss: 0.43848029782276343\n",
      "♯ Epoch: 24/80    |    💲Loss: 0.44132811750345563\n",
      "♯ Epoch: 24/80    |    💲Loss: 0.4448878304704875\n",
      "♯ Epoch: 24/80    |    💲Loss: 0.45525482092099145\n",
      "💰Validation Loss: 0.47075478732585907\n",
      "💰Validation Loss: 0.5444967358345443\n",
      "\n",
      "♯ Epoch: 25/80    |    💲Loss: 0.5855414122343063\n",
      "♯ Epoch: 25/80    |    💲Loss: 0.4891715736156053\n",
      "♯ Epoch: 25/80    |    💲Loss: 0.46850755369633584\n",
      "♯ Epoch: 25/80    |    💲Loss: 0.4612165899990603\n",
      "♯ Epoch: 25/80    |    💲Loss: 0.45710093035662264\n",
      "💰Validation Loss: 0.503124974668026\n",
      "💰Validation Loss: 0.43887897278412735\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 26/80    |    💲Loss: 0.4204052835702896\n",
      "♯ Epoch: 26/80    |    💲Loss: 0.44581923301857296\n",
      "♯ Epoch: 26/80    |    💲Loss: 0.44787844112003916\n",
      "♯ Epoch: 26/80    |    💲Loss: 0.44457296045045325\n",
      "♯ Epoch: 26/80    |    💲Loss: 0.4433756497853489\n",
      "💰Validation Loss: 0.47728051990270615\n",
      "💰Validation Loss: 0.43856513987083245\n",
      "\n",
      "♯ Epoch: 27/80    |    💲Loss: 0.4411030188202858\n",
      "♯ Epoch: 27/80    |    💲Loss: 0.4477153488683819\n",
      "♯ Epoch: 27/80    |    💲Loss: 0.4412264912875731\n",
      "♯ Epoch: 27/80    |    💲Loss: 0.4397335383558392\n",
      "♯ Epoch: 27/80    |    💲Loss: 0.4384463235197073\n",
      "💰Validation Loss: 0.4178370535373688\n",
      "💰Validation Loss: 0.4615706839036233\n",
      "\n",
      "♯ Epoch: 28/80    |    💲Loss: 0.4870968908071518\n",
      "♯ Epoch: 28/80    |    💲Loss: 0.4341619930202418\n",
      "♯ Epoch: 28/80    |    💲Loss: 0.4357488304376602\n",
      "♯ Epoch: 28/80    |    💲Loss: 0.4378009701389015\n",
      "♯ Epoch: 28/80    |    💲Loss: 0.4319273316605653\n",
      "💰Validation Loss: 0.6923755556344986\n",
      "💰Validation Loss: 0.46569918595844567\n",
      "\n",
      "♯ Epoch: 29/80    |    💲Loss: 0.31813371181488037\n",
      "♯ Epoch: 29/80    |    💲Loss: 0.42641279337429766\n",
      "♯ Epoch: 29/80    |    💲Loss: 0.42737981874440145\n",
      "♯ Epoch: 29/80    |    💲Loss: 0.43453300165699366\n",
      "♯ Epoch: 29/80    |    💲Loss: 0.4310195953155545\n",
      "💰Validation Loss: 0.39136771857738495\n",
      "💰Validation Loss: 0.43032391015255805\n",
      "\n",
      "♯ Epoch: 30/80    |    💲Loss: 0.44042993709445\n",
      "♯ Epoch: 30/80    |    💲Loss: 0.4299559264010427\n",
      "♯ Epoch: 30/80    |    💲Loss: 0.4239254064246345\n",
      "♯ Epoch: 30/80    |    💲Loss: 0.4198372679765636\n",
      "♯ Epoch: 30/80    |    💲Loss: 0.42258018499560784\n",
      "💰Validation Loss: 0.47662611305713654\n",
      "💰Validation Loss: 0.4370153095794491\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 31/80    |    💲Loss: 0.32068943977355957\n",
      "♯ Epoch: 31/80    |    💲Loss: 0.4012866301996873\n",
      "♯ Epoch: 31/80    |    💲Loss: 0.3920301980621631\n",
      "♯ Epoch: 31/80    |    💲Loss: 0.3869453136533796\n",
      "♯ Epoch: 31/80    |    💲Loss: 0.3866974851232663\n",
      "💰Validation Loss: 0.47404636442661285\n",
      "💰Validation Loss: 0.4012585288964876\n",
      "\n",
      "♯ Epoch: 32/80    |    💲Loss: 0.38120564818382263\n",
      "♯ Epoch: 32/80    |    💲Loss: 0.37636881884150575\n",
      "♯ Epoch: 32/80    |    💲Loss: 0.3892487030643136\n",
      "♯ Epoch: 32/80    |    💲Loss: 0.3819338073489872\n",
      "♯ Epoch: 32/80    |    💲Loss: 0.38221132443600014\n",
      "💰Validation Loss: 0.4034659117460251\n",
      "💰Validation Loss: 0.3957549958388404\n",
      "\n",
      "♯ Epoch: 33/80    |    💲Loss: 0.4654981195926666\n",
      "♯ Epoch: 33/80    |    💲Loss: 0.3885427014810024\n",
      "♯ Epoch: 33/80    |    💲Loss: 0.3868282138189273\n",
      "♯ Epoch: 33/80    |    💲Loss: 0.3835437546957569\n",
      "♯ Epoch: 33/80    |    💲Loss: 0.3814705537859713\n",
      "💰Validation Loss: 0.3239984028041363\n",
      "💰Validation Loss: 0.39215974421194283\n",
      "\n",
      "♯ Epoch: 34/80    |    💲Loss: 0.4911937713623047\n",
      "♯ Epoch: 34/80    |    💲Loss: 0.37439467363280826\n",
      "♯ Epoch: 34/80    |    💲Loss: 0.37029813684115365\n",
      "♯ Epoch: 34/80    |    💲Loss: 0.37228565537479036\n",
      "♯ Epoch: 34/80    |    💲Loss: 0.37434700059418813\n",
      "💰Validation Loss: 0.3790697753429413\n",
      "💰Validation Loss: 0.39664425313620283\n",
      "\n",
      "♯ Epoch: 35/80    |    💲Loss: 0.3033628687262535\n",
      "♯ Epoch: 35/80    |    💲Loss: 0.3701047417846057\n",
      "♯ Epoch: 35/80    |    💲Loss: 0.37757130057101523\n",
      "♯ Epoch: 35/80    |    💲Loss: 0.377829006671955\n",
      "♯ Epoch: 35/80    |    💲Loss: 0.3789772481200032\n",
      "💰Validation Loss: 0.47381819784641266\n",
      "💰Validation Loss: 0.39092313933490525\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 36/80    |    💲Loss: 0.3581755608320236\n",
      "♯ Epoch: 36/80    |    💲Loss: 0.3757505552234626\n",
      "♯ Epoch: 36/80    |    💲Loss: 0.3735983402500698\n",
      "♯ Epoch: 36/80    |    💲Loss: 0.3737457136676161\n",
      "♯ Epoch: 36/80    |    💲Loss: 0.37695289121713127\n",
      "💰Validation Loss: 0.28030040487647057\n",
      "💰Validation Loss: 0.3816079606514166\n",
      "\n",
      "♯ Epoch: 37/80    |    💲Loss: 0.36894403398036957\n",
      "♯ Epoch: 37/80    |    💲Loss: 0.37948735689025115\n",
      "♯ Epoch: 37/80    |    💲Loss: 0.3776797463941337\n",
      "♯ Epoch: 37/80    |    💲Loss: 0.3754176234275697\n",
      "♯ Epoch: 37/80    |    💲Loss: 0.3753473653070201\n",
      "💰Validation Loss: 0.26315387710928917\n",
      "💰Validation Loss: 0.38732108746719834\n",
      "\n",
      "♯ Epoch: 38/80    |    💲Loss: 0.5099834054708481\n",
      "♯ Epoch: 38/80    |    💲Loss: 0.37507832380435846\n",
      "♯ Epoch: 38/80    |    💲Loss: 0.3770969059800182\n",
      "♯ Epoch: 38/80    |    💲Loss: 0.3767855790972809\n",
      "♯ Epoch: 38/80    |    💲Loss: 0.3766236277088114\n",
      "💰Validation Loss: 0.3739185556769371\n",
      "💰Validation Loss: 0.3798286369863418\n",
      "\n",
      "♯ Epoch: 39/80    |    💲Loss: 0.4091076999902725\n",
      "♯ Epoch: 39/80    |    💲Loss: 0.3819658415816208\n",
      "♯ Epoch: 39/80    |    💲Loss: 0.37364705561182987\n",
      "♯ Epoch: 39/80    |    💲Loss: 0.37154361312324025\n",
      "♯ Epoch: 39/80    |    💲Loss: 0.3726448644314918\n",
      "💰Validation Loss: 0.48909808695316315\n",
      "💰Validation Loss: 0.3977123212696302\n",
      "\n",
      "♯ Epoch: 40/80    |    💲Loss: 0.26514827460050583\n",
      "♯ Epoch: 40/80    |    💲Loss: 0.3773097305162118\n",
      "♯ Epoch: 40/80    |    💲Loss: 0.3723364451260709\n",
      "♯ Epoch: 40/80    |    💲Loss: 0.37357777440642004\n",
      "♯ Epoch: 40/80    |    💲Loss: 0.3718957080972611\n",
      "💰Validation Loss: 0.42425302416086197\n",
      "💰Validation Loss: 0.3769318846303343\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 41/80    |    💲Loss: 0.2977644130587578\n",
      "♯ Epoch: 41/80    |    💲Loss: 0.3727143937260798\n",
      "♯ Epoch: 41/80    |    💲Loss: 0.3741423119767685\n",
      "♯ Epoch: 41/80    |    💲Loss: 0.37391852560852257\n",
      "♯ Epoch: 41/80    |    💲Loss: 0.3707012539251041\n",
      "💰Validation Loss: 0.38883768767118454\n",
      "💰Validation Loss: 0.37744365612247793\n",
      "\n",
      "♯ Epoch: 42/80    |    💲Loss: 0.40016186237335205\n",
      "♯ Epoch: 42/80    |    💲Loss: 0.36389806874022623\n",
      "♯ Epoch: 42/80    |    💲Loss: 0.36083017871599293\n",
      "♯ Epoch: 42/80    |    💲Loss: 0.3636490074094645\n",
      "♯ Epoch: 42/80    |    💲Loss: 0.3675117627566592\n",
      "💰Validation Loss: 0.33464474976062775\n",
      "💰Validation Loss: 0.38183843023558656\n",
      "\n",
      "♯ Epoch: 43/80    |    💲Loss: 0.4385966360569\n",
      "♯ Epoch: 43/80    |    💲Loss: 0.3596990891538634\n",
      "♯ Epoch: 43/80    |    💲Loss: 0.3666079326796888\n",
      "♯ Epoch: 43/80    |    💲Loss: 0.36807135626846965\n",
      "♯ Epoch: 43/80    |    💲Loss: 0.3688655412823259\n",
      "💰Validation Loss: 0.32079070806503296\n",
      "💰Validation Loss: 0.3695116627887629\n",
      "\n",
      "♯ Epoch: 44/80    |    💲Loss: 0.2783648855984211\n",
      "♯ Epoch: 44/80    |    💲Loss: 0.3636664104933786\n",
      "♯ Epoch: 44/80    |    💲Loss: 0.3660149169501974\n",
      "♯ Epoch: 44/80    |    💲Loss: 0.3703542935021494\n",
      "♯ Epoch: 44/80    |    💲Loss: 0.3718937895077274\n",
      "💰Validation Loss: 0.4921023100614548\n",
      "💰Validation Loss: 0.3844416190750233\n",
      "\n",
      "♯ Epoch: 45/80    |    💲Loss: 0.32301903143525124\n",
      "♯ Epoch: 45/80    |    💲Loss: 0.3525488029538405\n",
      "♯ Epoch: 45/80    |    💲Loss: 0.35931386788426645\n",
      "♯ Epoch: 45/80    |    💲Loss: 0.36669348853569095\n",
      "♯ Epoch: 45/80    |    💲Loss: 0.36946554124782655\n",
      "💰Validation Loss: 0.2974552512168884\n",
      "💰Validation Loss: 0.37795731670564353\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 46/80    |    💲Loss: 0.4604911506175995\n",
      "♯ Epoch: 46/80    |    💲Loss: 0.3713736403917912\n",
      "♯ Epoch: 46/80    |    💲Loss: 0.36930852178576873\n",
      "♯ Epoch: 46/80    |    💲Loss: 0.3681385597752475\n",
      "♯ Epoch: 46/80    |    💲Loss: 0.3670453166547336\n",
      "💰Validation Loss: 0.3655712157487869\n",
      "💰Validation Loss: 0.38415184827281695\n",
      "\n",
      "♯ Epoch: 47/80    |    💲Loss: 0.36132967844605446\n",
      "♯ Epoch: 47/80    |    💲Loss: 0.36799253691172246\n",
      "♯ Epoch: 47/80    |    💲Loss: 0.36233396900456344\n",
      "♯ Epoch: 47/80    |    💲Loss: 0.36433974886158377\n",
      "♯ Epoch: 47/80    |    💲Loss: 0.36660651488698776\n",
      "💰Validation Loss: 0.36175379902124405\n",
      "💰Validation Loss: 0.37484391026272634\n",
      "\n",
      "♯ Epoch: 48/80    |    💲Loss: 0.3705593943595886\n",
      "♯ Epoch: 48/80    |    💲Loss: 0.36359847242953164\n",
      "♯ Epoch: 48/80    |    💲Loss: 0.36438680446674276\n",
      "♯ Epoch: 48/80    |    💲Loss: 0.36804818316205\n",
      "♯ Epoch: 48/80    |    💲Loss: 0.3679804293499177\n",
      "💰Validation Loss: 0.29531754553318024\n",
      "💰Validation Loss: 0.3798102230608168\n",
      "\n",
      "♯ Epoch: 49/80    |    💲Loss: 0.32633496075868607\n",
      "♯ Epoch: 49/80    |    💲Loss: 0.36481163313261944\n",
      "♯ Epoch: 49/80    |    💲Loss: 0.3631218896242813\n",
      "♯ Epoch: 49/80    |    💲Loss: 0.36502517960916125\n",
      "♯ Epoch: 49/80    |    💲Loss: 0.3632535810984132\n",
      "💰Validation Loss: 0.2869591638445854\n",
      "💰Validation Loss: 0.3699975671191322\n",
      "\n",
      "♯ Epoch: 50/80    |    💲Loss: 0.39931000024080276\n",
      "♯ Epoch: 50/80    |    💲Loss: 0.3629860910633118\n",
      "♯ Epoch: 50/80    |    💲Loss: 0.3661455296313585\n",
      "♯ Epoch: 50/80    |    💲Loss: 0.3642002864125064\n",
      "♯ Epoch: 50/80    |    💲Loss: 0.36140697585544235\n",
      "💰Validation Loss: 0.3374447748064995\n",
      "💰Validation Loss: 0.38011477976152214\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 51/80    |    💲Loss: 0.3206818029284477\n",
      "♯ Epoch: 51/80    |    💲Loss: 0.37869747346359317\n",
      "♯ Epoch: 51/80    |    💲Loss: 0.36809947362067685\n",
      "♯ Epoch: 51/80    |    💲Loss: 0.36443906363433975\n",
      "♯ Epoch: 51/80    |    💲Loss: 0.3633441932991779\n",
      "💰Validation Loss: 0.3149527683854103\n",
      "💰Validation Loss: 0.37562577929901014\n",
      "\n",
      "♯ Epoch: 52/80    |    💲Loss: 0.386573888361454\n",
      "♯ Epoch: 52/80    |    💲Loss: 0.36813942903634345\n",
      "♯ Epoch: 52/80    |    💲Loss: 0.3668222636985245\n",
      "♯ Epoch: 52/80    |    💲Loss: 0.3651327790376851\n",
      "♯ Epoch: 52/80    |    💲Loss: 0.3649778412724671\n",
      "💰Validation Loss: 0.3791518956422806\n",
      "💰Validation Loss: 0.37964592291281957\n",
      "\n",
      "♯ Epoch: 53/80    |    💲Loss: 0.413950115442276\n",
      "♯ Epoch: 53/80    |    💲Loss: 0.35335400608358997\n",
      "♯ Epoch: 53/80    |    💲Loss: 0.35700919055634767\n",
      "♯ Epoch: 53/80    |    💲Loss: 0.3569649828975383\n",
      "♯ Epoch: 53/80    |    💲Loss: 0.35757305570634224\n",
      "💰Validation Loss: 0.2851236052811146\n",
      "💰Validation Loss: 0.3678182105321695\n",
      "\n",
      "♯ Epoch: 54/80    |    💲Loss: 0.5699584037065506\n",
      "♯ Epoch: 54/80    |    💲Loss: 0.3565895003404948\n",
      "♯ Epoch: 54/80    |    💲Loss: 0.3564894730178871\n",
      "♯ Epoch: 54/80    |    💲Loss: 0.3579236835897266\n",
      "♯ Epoch: 54/80    |    💲Loss: 0.3574859973303323\n",
      "💰Validation Loss: 0.3978959918022156\n",
      "💰Validation Loss: 0.37378211832135033\n",
      "\n",
      "♯ Epoch: 55/80    |    💲Loss: 0.3819224536418915\n",
      "♯ Epoch: 55/80    |    💲Loss: 0.35153045877814293\n",
      "♯ Epoch: 55/80    |    💲Loss: 0.3587239560166105\n",
      "♯ Epoch: 55/80    |    💲Loss: 0.3613413215438492\n",
      "♯ Epoch: 55/80    |    💲Loss: 0.3579164395605834\n",
      "💰Validation Loss: 0.39779555797576904\n",
      "💰Validation Loss: 0.3714806109961897\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 56/80    |    💲Loss: 0.37680019438266754\n",
      "♯ Epoch: 56/80    |    💲Loss: 0.3604125095955511\n",
      "♯ Epoch: 56/80    |    💲Loss: 0.3589039217606558\n",
      "♯ Epoch: 56/80    |    💲Loss: 0.3552471214961075\n",
      "♯ Epoch: 56/80    |    💲Loss: 0.35978136461070204\n",
      "💰Validation Loss: 0.308073315769434\n",
      "💰Validation Loss: 0.3655378554053236\n",
      "\n",
      "♯ Epoch: 57/80    |    💲Loss: 0.4153011590242386\n",
      "♯ Epoch: 57/80    |    💲Loss: 0.3596175775153212\n",
      "♯ Epoch: 57/80    |    💲Loss: 0.3635308390103318\n",
      "♯ Epoch: 57/80    |    💲Loss: 0.36075093605837155\n",
      "♯ Epoch: 57/80    |    💲Loss: 0.35898878665506245\n",
      "💰Validation Loss: 0.41209661215543747\n",
      "💰Validation Loss: 0.37440466984073717\n",
      "\n",
      "♯ Epoch: 58/80    |    💲Loss: 0.3863910138607025\n",
      "♯ Epoch: 58/80    |    💲Loss: 0.3565481974568107\n",
      "♯ Epoch: 58/80    |    💲Loss: 0.35396255076450495\n",
      "♯ Epoch: 58/80    |    💲Loss: 0.3552427543172508\n",
      "♯ Epoch: 58/80    |    💲Loss: 0.3567567953138503\n",
      "💰Validation Loss: 0.40347156673669815\n",
      "💰Validation Loss: 0.3734339850004947\n",
      "\n",
      "♯ Epoch: 59/80    |    💲Loss: 0.41438496112823486\n",
      "♯ Epoch: 59/80    |    💲Loss: 0.35406410115042536\n",
      "♯ Epoch: 59/80    |    💲Loss: 0.3592468937719936\n",
      "♯ Epoch: 59/80    |    💲Loss: 0.3576811252477458\n",
      "♯ Epoch: 59/80    |    💲Loss: 0.35683577454316795\n",
      "💰Validation Loss: 0.4410826563835144\n",
      "💰Validation Loss: 0.3622554458198276\n",
      "\n",
      "♯ Epoch: 60/80    |    💲Loss: 0.3576449900865555\n",
      "♯ Epoch: 60/80    |    💲Loss: 0.3577321601828726\n",
      "♯ Epoch: 60/80    |    💲Loss: 0.3525347423216152\n",
      "♯ Epoch: 60/80    |    💲Loss: 0.35923674562172436\n",
      "♯ Epoch: 60/80    |    💲Loss: 0.35869139816119633\n",
      "💰Validation Loss: 0.3990861624479294\n",
      "💰Validation Loss: 0.38094727619375923\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 61/80    |    💲Loss: 0.40918195247650146\n",
      "♯ Epoch: 61/80    |    💲Loss: 0.3450204034769299\n",
      "♯ Epoch: 61/80    |    💲Loss: 0.3561303838438804\n",
      "♯ Epoch: 61/80    |    💲Loss: 0.3561181956438032\n",
      "♯ Epoch: 61/80    |    💲Loss: 0.3571485666990131\n",
      "💰Validation Loss: 0.2612217143177986\n",
      "💰Validation Loss: 0.372103399366583\n",
      "\n",
      "♯ Epoch: 62/80    |    💲Loss: 0.3455720543861389\n",
      "♯ Epoch: 62/80    |    💲Loss: 0.36574209072064645\n",
      "♯ Epoch: 62/80    |    💲Loss: 0.35986831378358514\n",
      "♯ Epoch: 62/80    |    💲Loss: 0.3602763105654142\n",
      "♯ Epoch: 62/80    |    💲Loss: 0.3587829791278836\n",
      "💰Validation Loss: 0.4651564806699753\n",
      "💰Validation Loss: 0.3742977999298289\n",
      "\n",
      "♯ Epoch: 63/80    |    💲Loss: 0.37407658994197845\n",
      "♯ Epoch: 63/80    |    💲Loss: 0.34939343605817547\n",
      "♯ Epoch: 63/80    |    💲Loss: 0.3591364086860448\n",
      "♯ Epoch: 63/80    |    💲Loss: 0.35841627363920014\n",
      "♯ Epoch: 63/80    |    💲Loss: 0.36013098185106257\n",
      "💰Validation Loss: 0.3018835410475731\n",
      "💰Validation Loss: 0.37633024373709567\n",
      "\n",
      "♯ Epoch: 64/80    |    💲Loss: 0.22632070630788803\n",
      "♯ Epoch: 64/80    |    💲Loss: 0.35794773424911025\n",
      "♯ Epoch: 64/80    |    💲Loss: 0.35730661796544916\n",
      "♯ Epoch: 64/80    |    💲Loss: 0.3551571249677196\n",
      "♯ Epoch: 64/80    |    💲Loss: 0.35427142034500764\n",
      "💰Validation Loss: 0.5283739790320396\n",
      "💰Validation Loss: 0.374054482077608\n",
      "\n",
      "♯ Epoch: 65/80    |    💲Loss: 0.3645116090774536\n",
      "♯ Epoch: 65/80    |    💲Loss: 0.3601819917670276\n",
      "♯ Epoch: 65/80    |    💲Loss: 0.3567570388984324\n",
      "♯ Epoch: 65/80    |    💲Loss: 0.35802276350211265\n",
      "♯ Epoch: 65/80    |    💲Loss: 0.3586805621649782\n",
      "💰Validation Loss: 0.3573620952665806\n",
      "💰Validation Loss: 0.37017416970638356\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 66/80    |    💲Loss: 0.34839989244937897\n",
      "♯ Epoch: 66/80    |    💲Loss: 0.35799244887167864\n",
      "♯ Epoch: 66/80    |    💲Loss: 0.3582382091038411\n",
      "♯ Epoch: 66/80    |    💲Loss: 0.3595961321739362\n",
      "♯ Epoch: 66/80    |    💲Loss: 0.3565359614984576\n",
      "💰Validation Loss: 0.4286186248064041\n",
      "💰Validation Loss: 0.3799240347551237\n",
      "\n",
      "♯ Epoch: 67/80    |    💲Loss: 0.33755212277173996\n",
      "♯ Epoch: 67/80    |    💲Loss: 0.3540255169725359\n",
      "♯ Epoch: 67/80    |    💲Loss: 0.35829343391925245\n",
      "♯ Epoch: 67/80    |    💲Loss: 0.3573111684627806\n",
      "♯ Epoch: 67/80    |    💲Loss: 0.356107859586614\n",
      "💰Validation Loss: 0.32569975033402443\n",
      "💰Validation Loss: 0.3645086985560927\n",
      "\n",
      "♯ Epoch: 68/80    |    💲Loss: 0.49497778713703156\n",
      "♯ Epoch: 68/80    |    💲Loss: 0.3629155833421662\n",
      "♯ Epoch: 68/80    |    💲Loss: 0.3590647000726776\n",
      "♯ Epoch: 68/80    |    💲Loss: 0.3572063915419123\n",
      "♯ Epoch: 68/80    |    💲Loss: 0.35651652745791057\n",
      "💰Validation Loss: 0.4557223469018936\n",
      "💰Validation Loss: 0.3726141694011075\n",
      "\n",
      "♯ Epoch: 69/80    |    💲Loss: 0.33574187010526657\n",
      "♯ Epoch: 69/80    |    💲Loss: 0.35119383151430894\n",
      "♯ Epoch: 69/80    |    💲Loss: 0.3550840146580146\n",
      "♯ Epoch: 69/80    |    💲Loss: 0.35695581470439797\n",
      "♯ Epoch: 69/80    |    💲Loss: 0.35697337126642686\n",
      "💰Validation Loss: 0.3913835808634758\n",
      "💰Validation Loss: 0.37341745313957775\n",
      "\n",
      "♯ Epoch: 70/80    |    💲Loss: 0.31963616609573364\n",
      "♯ Epoch: 70/80    |    💲Loss: 0.34793063089030213\n",
      "♯ Epoch: 70/80    |    💲Loss: 0.35211669164362236\n",
      "♯ Epoch: 70/80    |    💲Loss: 0.3528230703432744\n",
      "♯ Epoch: 70/80    |    💲Loss: 0.353670066210936\n",
      "💰Validation Loss: 0.440631702542305\n",
      "💰Validation Loss: 0.37004922450252686\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 71/80    |    💲Loss: 0.40186624974012375\n",
      "♯ Epoch: 71/80    |    💲Loss: 0.3618383409068136\n",
      "♯ Epoch: 71/80    |    💲Loss: 0.36343620903789997\n",
      "♯ Epoch: 71/80    |    💲Loss: 0.36174060538584407\n",
      "♯ Epoch: 71/80    |    💲Loss: 0.362457363060362\n",
      "💰Validation Loss: 0.30258581787347794\n",
      "💰Validation Loss: 0.36978399111787874\n",
      "\n",
      "♯ Epoch: 72/80    |    💲Loss: 0.32725390046834946\n",
      "♯ Epoch: 72/80    |    💲Loss: 0.3657318307547876\n",
      "♯ Epoch: 72/80    |    💲Loss: 0.3578317867341771\n",
      "♯ Epoch: 72/80    |    💲Loss: 0.35485218931917734\n",
      "♯ Epoch: 72/80    |    💲Loss: 0.3546554299299036\n",
      "💰Validation Loss: 0.32539094239473343\n",
      "💰Validation Loss: 0.36559817971348174\n",
      "\n",
      "♯ Epoch: 73/80    |    💲Loss: 0.36494598165154457\n",
      "♯ Epoch: 73/80    |    💲Loss: 0.3623716356693813\n",
      "♯ Epoch: 73/80    |    💲Loss: 0.36356308669852677\n",
      "♯ Epoch: 73/80    |    💲Loss: 0.3619551520509973\n",
      "♯ Epoch: 73/80    |    💲Loss: 0.36155684520850456\n",
      "💰Validation Loss: 0.4043305143713951\n",
      "💰Validation Loss: 0.37168548562296544\n",
      "\n",
      "♯ Epoch: 74/80    |    💲Loss: 0.33713775873184204\n",
      "♯ Epoch: 74/80    |    💲Loss: 0.35525772598857924\n",
      "♯ Epoch: 74/80    |    💲Loss: 0.35353840721669183\n",
      "♯ Epoch: 74/80    |    💲Loss: 0.3553059511814898\n",
      "♯ Epoch: 74/80    |    💲Loss: 0.35825057845200386\n",
      "💰Validation Loss: 0.40731102228164673\n",
      "💰Validation Loss: 0.3733038028868118\n",
      "\n",
      "♯ Epoch: 75/80    |    💲Loss: 0.37487971782684326\n",
      "♯ Epoch: 75/80    |    💲Loss: 0.3721357761780814\n",
      "♯ Epoch: 75/80    |    💲Loss: 0.36107437230127665\n",
      "♯ Epoch: 75/80    |    💲Loss: 0.36244958929989823\n",
      "♯ Epoch: 75/80    |    💲Loss: 0.35843516421269744\n",
      "💰Validation Loss: 0.3748895600438118\n",
      "💰Validation Loss: 0.36641477929926153\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n",
      "♯ Epoch: 76/80    |    💲Loss: 0.32970305532217026\n",
      "♯ Epoch: 76/80    |    💲Loss: 0.35764602060881584\n",
      "♯ Epoch: 76/80    |    💲Loss: 0.3555914149318465\n",
      "♯ Epoch: 76/80    |    💲Loss: 0.3554595893069458\n",
      "♯ Epoch: 76/80    |    💲Loss: 0.3572229364761465\n",
      "💰Validation Loss: 0.32519690692424774\n",
      "💰Validation Loss: 0.3675161689372346\n",
      "\n",
      "♯ Epoch: 77/80    |    💲Loss: 0.31962818652391434\n",
      "♯ Epoch: 77/80    |    💲Loss: 0.36266203479159\n",
      "♯ Epoch: 77/80    |    💲Loss: 0.3597959413457273\n",
      "♯ Epoch: 77/80    |    💲Loss: 0.3604963700475784\n",
      "♯ Epoch: 77/80    |    💲Loss: 0.3573608500952658\n",
      "💰Validation Loss: 0.4625236913561821\n",
      "💰Validation Loss: 0.36997474855420615\n",
      "\n",
      "♯ Epoch: 78/80    |    💲Loss: 0.4668663591146469\n",
      "♯ Epoch: 78/80    |    💲Loss: 0.36617493279056973\n",
      "♯ Epoch: 78/80    |    💲Loss: 0.3580496709849407\n",
      "♯ Epoch: 78/80    |    💲Loss: 0.35747592424064184\n",
      "♯ Epoch: 78/80    |    💲Loss: 0.35729504132322837\n",
      "💰Validation Loss: 0.432453416287899\n",
      "💰Validation Loss: 0.3719505840857135\n",
      "\n",
      "♯ Epoch: 79/80    |    💲Loss: 0.38828109204769135\n",
      "♯ Epoch: 79/80    |    💲Loss: 0.36305080911163057\n",
      "♯ Epoch: 79/80    |    💲Loss: 0.3596326384174438\n",
      "♯ Epoch: 79/80    |    💲Loss: 0.35948989559521904\n",
      "♯ Epoch: 79/80    |    💲Loss: 0.35805535716866316\n",
      "💰Validation Loss: 0.3723871484398842\n",
      "💰Validation Loss: 0.37233083689640656\n",
      "\n",
      "♯ Epoch: 80/80    |    💲Loss: 0.39144088327884674\n",
      "♯ Epoch: 80/80    |    💲Loss: 0.3573803494656735\n",
      "♯ Epoch: 80/80    |    💲Loss: 0.3592557751698725\n",
      "♯ Epoch: 80/80    |    💲Loss: 0.360400678750833\n",
      "♯ Epoch: 80/80    |    💲Loss: 0.3602570942196614\n",
      "💰Validation Loss: 0.2956685535609722\n",
      "💰Validation Loss: 0.3702911334388917\n",
      "\n",
      "╔═══════════════════════╗\n",
      "║ Save checkpoint ..... ║\n",
      "╚═══════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "print(\"╔══════════════════════╗\\n║ Start training ..... ║\\n╚══════════════════════╝\")\n",
    "trainer = Trainer(ckptroot,\n",
    "                  model,\n",
    "                  device,\n",
    "                  epochs,\n",
    "                  criterion,\n",
    "                  optimizer,\n",
    "                  scheduler,\n",
    "                  start_epoch,\n",
    "                  trainloader,\n",
    "                  validationloader)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
